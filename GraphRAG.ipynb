{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "623dc5be",
   "metadata": {},
   "source": [
    "**Author:** Shahed Sabab  \n",
    "**Tech Stack:** Neo4j, Langchain, Ollama  \n",
    "\n",
    "---\n",
    "\n",
    "## Content Summary\n",
    "\n",
    "This notebook provides an implementation of a Hybrid Retrieval-Augmented Generation (RAG) model combining two approaches: Knowledge Graph-based retrieval and Naive RAG. The model leverages the strengths of graph databases like Neo4j for structured retrieval alongside unstructured document retrieval methods (naive RAG) to create a more efficient and versatile information retrieval system.\n",
    "\n",
    "### Key Concepts:\n",
    "\n",
    "1. **Knowledge Graph (KG) RAG**:\n",
    "   - Utilizes graph-based data structures for storing and retrieving information.\n",
    "   - Powered by Neo4j to enable the use of relationships and connections within the data to enhance query results.\n",
    "   \n",
    "2. **Naive RAG**:\n",
    "   - A simple document-based RAG that relies on unstructured data.\n",
    "   - This method allows the system to perform searches across a corpus without needing predefined relations.\n",
    "   \n",
    "3. **Langchain Integration**:\n",
    "   - Facilitates the chaining of various modules in the pipeline for language model interaction.\n",
    "   - Allows smooth interaction with Neo4j and the document retrieval system.\n",
    "   \n",
    "4. **Ollama Integration**:\n",
    "   - Ollama models for local LLM support\n",
    "\n",
    "5. **Gradio UI Integration**:\n",
    "   - A user-friendly web interface is built using Gradio, allowing interaction with the Hybrid RAG model through a simple, accessible UI. \n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de262b61",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"figure/GraphRAG.png\" alt=\"Hybrid RAG Diagram\" width=\"1200\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8aa865",
   "metadata": {},
   "source": [
    "# Define packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "b8257f2b-6b55-47c1-942a-edb41ec3ef0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.documents import Document\n",
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "from langchain.chains import GraphCypherQAChain\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_community.vectorstores import Neo4jVector\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import  RunnablePassthrough\n",
    "from langchain_community.vectorstores.neo4j_vector import remove_lucene_chars\n",
    "import json \n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_ollama import ChatOllama\n",
    "from neo4j import GraphDatabase\n",
    "from langchain_experimental.llms.ollama_functions import OllamaFunctions\n",
    "import gradio as gr\n",
    "# Load environment variables from .env file\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# Access the variables\n",
    "neo4j_uri = os.getenv('NEO4J_URI')\n",
    "neo4j_username = os.getenv('NEO4J_USERNAME')\n",
    "neo4j_password = os.getenv('NEO4J_PASSWORD')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3a3d94",
   "metadata": {},
   "source": [
    "# Neo4j Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "3bf1b8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "graph=Neo4jGraph()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af852b1",
   "metadata": {},
   "source": [
    "# Local llm model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "83b81187",
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama_llm = OllamaFunctions(model=\"gemma2:9b\", temperature=0, format=\"json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "69db3de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=ollama_llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18817ed1",
   "metadata": {},
   "source": [
    "# Text splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "f7db93bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loader = TextLoader(file_path=\"input/dummy_text.txt\")\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=250, chunk_overlap=24)\n",
    "documents = text_splitter.split_documents(documents=docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "9d5beb6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'input/dummy_text.txt'}, page_content='I met Geoffrey Hinton at his house on a pretty street in north London just four days before the bombshell \\nannouncement that he is quitting Google. Hinton is a pioneer of deep learning who helped develop'),\n",
       " Document(metadata={'source': 'input/dummy_text.txt'}, page_content='some of the most important techniques at the heart of modern artificial intelligence, \\nbut after a decade at Google, he is stepping down to focus on new concerns he now has about AI.'),\n",
       " Document(metadata={'source': 'input/dummy_text.txt'}, page_content='Stunned by the capabilities of new large language models, \\nHinton wants to raise public awareness of the serious risks that he now believes may accompany the technology he ushered in.'),\n",
       " Document(metadata={'source': 'input/dummy_text.txt'}, page_content='At the start of our conversation, I took a seat at the kitchen table, and Hinton started pacing. \\nPlagued for years by chronic back pain, Hinton almost never sits down.'),\n",
       " Document(metadata={'source': 'input/dummy_text.txt'}, page_content='For the next hour I watched him walk from one end of the room to the other, my head swiveling as he spoke. \\nAnd he had plenty to say.'),\n",
       " Document(metadata={'source': 'input/dummy_text.txt'}, page_content='The 75-year-old computer scientist, who was a joint recipient with Yann LeCun and Yoshua Bengio of the 2018 Turing Award \\nfor his work on deep learning, says he is ready to shift gears.'),\n",
       " Document(metadata={'source': 'input/dummy_text.txt'}, page_content=\"“I'm getting too old to do technical work that requires remembering lots of details,” he told me. \\n“I’m still okay, but I’m not nearly as good as I was, and that’s annoying.”\"),\n",
       " Document(metadata={'source': 'input/dummy_text.txt'}, page_content='Widely regarded as the “godfather of AI,” Hinton shared the Noble prize with John J. Hopfield \\nfor foundational discoveries and inventions that enable machine learning with artificial neural networks.')]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974b14f6",
   "metadata": {},
   "source": [
    "# Graph Transformer (convert documents-> graph documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "ae0f0c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the LLMGraphTransformer\n",
    "llm_transformer = LLMGraphTransformer(llm=llm)\n",
    "\n",
    "# Convert the document to a graph\n",
    "graph_documents = llm_transformer.convert_to_graph_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "4d474240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphDocument(nodes=[Node(id='Some Of The Most Important Techniques At The Heart Of Modern Artificial Intelligence', type='Concept', properties={}), Node(id='He', type='Person', properties={}), Node(id='Google', type='Organization', properties={})], relationships=[Relationship(source=Node(id='He', type='Person', properties={}), target=Node(id='Some Of The Most Important Techniques At The Heart Of Modern Artificial Intelligence', type='Concept', properties={}), type='RELATED_TO', properties={}), Relationship(source=Node(id='He', type='Person', properties={}), target=Node(id='Google', type='Organization', properties={}), type='WORKED_AT', properties={})], source=Document(metadata={'source': 'input/dummy_text.txt'}, page_content='some of the most important techniques at the heart of modern artificial intelligence, \\nbut after a decade at Google, he is stepping down to focus on new concerns he now has about AI.'))"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_documents[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "c1484bc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Node(id='Some Of The Most Important Techniques At The Heart Of Modern Artificial Intelligence', type='Concept', properties={}),\n",
       " Node(id='He', type='Person', properties={}),\n",
       " Node(id='Google', type='Organization', properties={})]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_documents[1].nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "e74668fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Relationship(source=Node(id='He', type='Person', properties={}), target=Node(id='Some Of The Most Important Techniques At The Heart Of Modern Artificial Intelligence', type='Concept', properties={}), type='RELATED_TO', properties={}),\n",
       " Relationship(source=Node(id='He', type='Person', properties={}), target=Node(id='Google', type='Organization', properties={}), type='WORKED_AT', properties={})]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_documents[1].relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd941a73",
   "metadata": {},
   "source": [
    "# Push graph to Neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "3d2b44b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph data has been successfully pushed to Neo4j.\n"
     ]
    }
   ],
   "source": [
    "# Use the add_graph_documents method to push the data\n",
    "graph.add_graph_documents(\n",
    "    graph_documents=graph_documents,  # Your graph_document goes here\n",
    "    include_source=True,  # Set to True if you want to include the source document\n",
    "    baseEntityLabel=True  # Set to True to add a base label to all entities\n",
    ")\n",
    "\n",
    "print(\"Graph data has been successfully pushed to Neo4j.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7264d575",
   "metadata": {},
   "source": [
    "# Vector retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "1b1fa4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama_embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "676935c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL (row) { ... }} {position: line: 1, column: 21, offset: 20} for query: \"UNWIND $data AS row CALL { WITH row MERGE (c:`Chunk` {id: row.id}) WITH c, row CALL db.create.setNodeVectorProperty(c, 'embedding', row.embedding) SET c.`text` = row.text SET c += row.metadata } IN TRANSACTIONS OF 1000 ROWS \"\n"
     ]
    }
   ],
   "source": [
    "db = Neo4jVector.from_documents(\n",
    "    documents, \n",
    "    ollama_embeddings, \n",
    "    url=neo4j_uri,\n",
    "    username=neo4j_username, \n",
    "    password=neo4j_password\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "13c5af57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Score:  0.8407111167907715\n",
      "Widely regarded as the “godfather of AI,” Hinton shared the Noble prize with John J. Hopfield \n",
      "for foundational discoveries and inventions that enable machine learning with artificial neural networks.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "query = \"who is hinton\"\n",
    "docs_with_score = db.similarity_search_with_score(query, k=1)\n",
    "for doc, score in docs_with_score:\n",
    "    print(\"-\" * 80)\n",
    "    print(\"Score: \", score)\n",
    "    print(doc.page_content)\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "df7f6340",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_index = Neo4jVector.from_existing_graph(\n",
    "    ollama_embeddings,\n",
    "    search_type=\"hybrid\",\n",
    "    node_label=\"Document\",\n",
    "    text_node_properties=[\"text\"],\n",
    "    embedding_node_property=\"embedding\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "dc2c0e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_retriever(question, top_k=1):\n",
    "    vector_ret = vector_index.as_retriever(k=top_k)\n",
    "    return [el.page_content for el in vector_ret.invoke(question)][:top_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "6bec96e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = GraphDatabase.driver(\n",
    "    uri = neo4j_uri,\n",
    "    auth = (neo4j_username,\n",
    "            neo4j_password))\n",
    "\n",
    "def create_fulltext_index(tx):\n",
    "    query = '''\n",
    "    CREATE FULLTEXT INDEX `fulltext_entity_id` \n",
    "    FOR (n:__Entity__) \n",
    "    ON EACH [n.id];\n",
    "    '''\n",
    "    tx.run(query)\n",
    "\n",
    "# Function to execute the query\n",
    "def create_index():\n",
    "    with driver.session() as session:\n",
    "        session.execute_write(create_fulltext_index)\n",
    "        print(\"Fulltext index created successfully.\")\n",
    "\n",
    "# Call the function to create the index\n",
    "try:\n",
    "    create_index()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Close the driver connection\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea25d20",
   "metadata": {},
   "source": [
    "# Graph retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "36ad127e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Entities(BaseModel):\n",
    "    \"\"\"Identifying information about entities.\"\"\"\n",
    "\n",
    "    names: list[str] = Field(\n",
    "        ...,\n",
    "        description=\"All the person, organization, or business entities that \"\n",
    "        \"appear in the text\",\n",
    "    )\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are extracting organization and person entities from the text.\",\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"Use the given format to extract information from the following \"\n",
    "            \"input: {question}\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "entity_chain = llm.with_structured_output(Entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "66c05b94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Entities(names=['hinton'])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_chain.invoke(\"Who is hinton?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "73587931",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_full_text_query(input: str) -> str:\n",
    "    words = [el for el in remove_lucene_chars(input).split() if el]\n",
    "    if not words:\n",
    "        return \"\"\n",
    "    full_text_query = \" AND \".join([f\"{word}~2\" for word in words])\n",
    "    print(f\"Generated Query: {full_text_query}\")\n",
    "    return full_text_query.strip()\n",
    "\n",
    "\n",
    "# Fulltext index query\n",
    "def graph_retriever(question: str) -> str:\n",
    "    \"\"\"\n",
    "    Collects the neighborhood of entities mentioned\n",
    "    in the question\n",
    "    \"\"\"\n",
    "    result = \"\"\n",
    "    # detect entity through entity chain and pass it to graph query\n",
    "    entities = entity_chain.invoke(question)\n",
    "    for entity in entities.names:\n",
    "        response = graph.query(\n",
    "            \"\"\"\n",
    "            CALL db.index.fulltext.queryNodes('fulltext_entity_id', $query, {limit:2})\n",
    "            YIELD node,score\n",
    "            CALL {\n",
    "              WITH node\n",
    "              MATCH (node)-[r:!MENTIONS]->(neighbor)\n",
    "              RETURN node.id + ' - ' + type(r) + ' -> ' + neighbor.id AS output\n",
    "              UNION ALL\n",
    "              WITH node\n",
    "              MATCH (node)<-[r:!MENTIONS]-(neighbor)\n",
    "              RETURN neighbor.id + ' - ' + type(r) + ' -> ' +  node.id AS output\n",
    "            }\n",
    "            RETURN output LIMIT 50\n",
    "            \"\"\",\n",
    "            {\"query\": entity},\n",
    "        )\n",
    "        result += \"\\n\".join([el['output'] for el in response])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "4bf60b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL (node, node) { ... }} {position: line: 4, column: 13, offset: 129} for query: \"\\n            CALL db.index.fulltext.queryNodes('fulltext_entity_id', $query, {limit:2})\\n            YIELD node,score\\n            CALL {\\n              WITH node\\n              MATCH (node)-[r:!MENTIONS]->(neighbor)\\n              RETURN node.id + ' - ' + type(r) + ' -> ' + neighbor.id AS output\\n              UNION ALL\\n              WITH node\\n              MATCH (node)<-[r:!MENTIONS]-(neighbor)\\n              RETURN neighbor.id + ' - ' + type(r) + ' -> ' +  node.id AS output\\n            }\\n            RETURN output LIMIT 50\\n            \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hinton - STUNNED_BY -> Large Language Models\n",
      "Hinton - AT -> Kitchen Table\n",
      "Hinton - BELIEVES -> Risks\n",
      "Geoffrey Hinton - WORKS_FOR -> Google\n",
      "Geoffrey Hinton - SHARED_AWARD -> Yann Lecun\n",
      "Geoffrey Hinton - SHARED_AWARD -> Yoshua Bengio\n",
      "Geoffrey Hinton - RECEIVED -> Turing Award\n",
      "Geoffrey Hinton - LIVES_IN -> North London\n",
      "Geoffrey Hinton - SHARED_NOBLE_PRIZE -> John J. Hopfield\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(graph_retriever(\"Who is hinton\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fd9c20",
   "metadata": {},
   "source": [
    "# Hybrid Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "61152587",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_retriever(question: str):\n",
    "    graph_data = graph_retriever(question)\n",
    "    vector_data = vector_retriever(question)\n",
    "    final_data = f\"\"\"\n",
    "    GRAPH DATA:\n",
    "    {graph_data}\n",
    "    VECTOR DATA:\n",
    "    {\"#Document \". join(vector_data)}\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"final_data\": final_data,\n",
    "        \"graph_data\": graph_data,\n",
    "        \"vector_data\": vector_data\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "160f0d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "Question: {question}\n",
    "Only generate your response from the context. Do not make anything up.\n",
    "Add as much information as needed to generate a coherent and informative response \n",
    "based on the context. \n",
    "Answer:\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "chain = (\n",
    "        {\n",
    "            \"context\": lambda x: hybrid_retriever(x)[\"final_data\"],\n",
    "            \"question\": RunnablePassthrough(),\n",
    "        }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "223d4c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def invoke_chain(query):\n",
    "    retriever_output = hybrid_retriever(query)\n",
    "    response = chain.invoke(query)\n",
    "    return {\n",
    "        \"response\": response,\n",
    "        \"graph_data\": retriever_output[\"graph_data\"],\n",
    "        \"vector_data\": retriever_output[\"vector_data\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "6adc5e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7875\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7875/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL (node, node) { ... }} {position: line: 4, column: 13, offset: 129} for query: \"\\n            CALL db.index.fulltext.queryNodes('fulltext_entity_id', $query, {limit:2})\\n            YIELD node,score\\n            CALL {\\n              WITH node\\n              MATCH (node)-[r:!MENTIONS]->(neighbor)\\n              RETURN node.id + ' - ' + type(r) + ' -> ' + neighbor.id AS output\\n              UNION ALL\\n              WITH node\\n              MATCH (node)<-[r:!MENTIONS]-(neighbor)\\n              RETURN neighbor.id + ' - ' + type(r) + ' -> ' +  node.id AS output\\n            }\\n            RETURN output LIMIT 50\\n            \"\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL () { ... }} {position: line: 1, column: 1, offset: 0} for query: \"CALL { CALL db.index.vector.queryNodes($index, $k, $embedding) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS max UNWIND nodes AS n RETURN n.node AS node, (n.score / max) AS score UNION CALL db.index.fulltext.queryNodes($keyword_index, $query, {limit: $k}) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS max UNWIND nodes AS n RETURN n.node AS node, (n.score / max) AS score } WITH node, max(score) AS score ORDER BY score DESC LIMIT $k RETURN reduce(str='', k IN ['text'] | str + '\\\\n' + k + ': ' + coalesce(node[k], '')) AS text, node {.*, `embedding`: Null, id: Null, `text`: Null} AS metadata, score\"\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL (node, node) { ... }} {position: line: 4, column: 13, offset: 129} for query: \"\\n            CALL db.index.fulltext.queryNodes('fulltext_entity_id', $query, {limit:2})\\n            YIELD node,score\\n            CALL {\\n              WITH node\\n              MATCH (node)-[r:!MENTIONS]->(neighbor)\\n              RETURN node.id + ' - ' + type(r) + ' -> ' + neighbor.id AS output\\n              UNION ALL\\n              WITH node\\n              MATCH (node)<-[r:!MENTIONS]-(neighbor)\\n              RETURN neighbor.id + ' - ' + type(r) + ' -> ' +  node.id AS output\\n            }\\n            RETURN output LIMIT 50\\n            \"\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL () { ... }} {position: line: 1, column: 1, offset: 0} for query: \"CALL { CALL db.index.vector.queryNodes($index, $k, $embedding) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS max UNWIND nodes AS n RETURN n.node AS node, (n.score / max) AS score UNION CALL db.index.fulltext.queryNodes($keyword_index, $query, {limit: $k}) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS max UNWIND nodes AS n RETURN n.node AS node, (n.score / max) AS score } WITH node, max(score) AS score ORDER BY score DESC LIMIT $k RETURN reduce(str='', k IN ['text'] | str + '\\\\n' + k + ': ' + coalesce(node[k], '')) AS text, node {.*, `embedding`: Null, id: Null, `text`: Null} AS metadata, score\"\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL (node, node) { ... }} {position: line: 4, column: 13, offset: 129} for query: \"\\n            CALL db.index.fulltext.queryNodes('fulltext_entity_id', $query, {limit:2})\\n            YIELD node,score\\n            CALL {\\n              WITH node\\n              MATCH (node)-[r:!MENTIONS]->(neighbor)\\n              RETURN node.id + ' - ' + type(r) + ' -> ' + neighbor.id AS output\\n              UNION ALL\\n              WITH node\\n              MATCH (node)<-[r:!MENTIONS]-(neighbor)\\n              RETURN neighbor.id + ' - ' + type(r) + ' -> ' +  node.id AS output\\n            }\\n            RETURN output LIMIT 50\\n            \"\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL () { ... }} {position: line: 1, column: 1, offset: 0} for query: \"CALL { CALL db.index.vector.queryNodes($index, $k, $embedding) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS max UNWIND nodes AS n RETURN n.node AS node, (n.score / max) AS score UNION CALL db.index.fulltext.queryNodes($keyword_index, $query, {limit: $k}) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS max UNWIND nodes AS n RETURN n.node AS node, (n.score / max) AS score } WITH node, max(score) AS score ORDER BY score DESC LIMIT $k RETURN reduce(str='', k IN ['text'] | str + '\\\\n' + k + ': ' + coalesce(node[k], '')) AS text, node {.*, `embedding`: Null, id: Null, `text`: Null} AS metadata, score\"\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL (node, node) { ... }} {position: line: 4, column: 13, offset: 129} for query: \"\\n            CALL db.index.fulltext.queryNodes('fulltext_entity_id', $query, {limit:2})\\n            YIELD node,score\\n            CALL {\\n              WITH node\\n              MATCH (node)-[r:!MENTIONS]->(neighbor)\\n              RETURN node.id + ' - ' + type(r) + ' -> ' + neighbor.id AS output\\n              UNION ALL\\n              WITH node\\n              MATCH (node)<-[r:!MENTIONS]-(neighbor)\\n              RETURN neighbor.id + ' - ' + type(r) + ' -> ' +  node.id AS output\\n            }\\n            RETURN output LIMIT 50\\n            \"\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL () { ... }} {position: line: 1, column: 1, offset: 0} for query: \"CALL { CALL db.index.vector.queryNodes($index, $k, $embedding) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS max UNWIND nodes AS n RETURN n.node AS node, (n.score / max) AS score UNION CALL db.index.fulltext.queryNodes($keyword_index, $query, {limit: $k}) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS max UNWIND nodes AS n RETURN n.node AS node, (n.score / max) AS score } WITH node, max(score) AS score ORDER BY score DESC LIMIT $k RETURN reduce(str='', k IN ['text'] | str + '\\\\n' + k + ': ' + coalesce(node[k], '')) AS text, node {.*, `embedding`: Null, id: Null, `text`: Null} AS metadata, score\"\n"
     ]
    }
   ],
   "source": [
    "def gradio_interface(query):\n",
    "    result = invoke_chain(query)\n",
    "    return (\n",
    "        result[\"response\"],\n",
    "        str(result[\"graph_data\"]),\n",
    "        \"\\n\".join(result[\"vector_data\"])\n",
    "    )\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# GraphRAG Query Interface\")\n",
    "    \n",
    "    query_input = gr.Textbox(lines=2, placeholder=\"Enter your query here...\")\n",
    "    submit_btn = gr.Button(\"Submit\")\n",
    "    \n",
    "    with gr.Column():\n",
    "        response_output = gr.Textbox(label=\"Model Response\")\n",
    "        \n",
    "        with gr.Accordion(\"Graph Data\", open=True):\n",
    "            graph_data_output = gr.Textbox(label=\"Graph Data\")\n",
    "        \n",
    "        with gr.Accordion(\"Vector Data\", open=True):\n",
    "            vector_data_output = gr.Textbox(label=\"Vector Data\")\n",
    "    \n",
    "    submit_btn.click(\n",
    "        fn=gradio_interface,\n",
    "        inputs=query_input,\n",
    "        outputs=[response_output, graph_data_output, vector_data_output]\n",
    "    )\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcaa8948",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad3d732",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multiagent-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
